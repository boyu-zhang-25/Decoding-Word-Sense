{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import string\n",
    "import itertools\n",
    "from io import open\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Iterable, defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set determinstic results\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Device: cpu\n",
      "0\n",
      "Size of vocab: 49036\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "elmo = ElmoEmbedder()\n",
    "\n",
    "from encoder import *\n",
    "from decoder import *\n",
    "from emb2seq_model import *\n",
    "\n",
    "# get the decoder vocab\n",
    "with open('./data/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    print(\"Size of vocab: {}\".format(vocab.idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emb2Seq_Model(\n",
       "  (encoder): Encoder(\n",
       "    (dimension_reduction): Linear(in_features=3072, out_features=512, bias=True)\n",
       "    (lstm): LSTM(512, 256, num_layers=2, bidirectional=True)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=300, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0)\n",
       "      (3): Linear(in_features=300, out_features=256, bias=True)\n",
       "      (4): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm_cell): LSTMCell(512, 256)\n",
       "    (linear): Linear(in_features=256, out_features=49036, bias=True)\n",
       "  )\n",
       "  (embed): Embedding(49036, 256, padding_idx=0)\n",
       "  (dropout): Dropout(p=0)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size = vocab.idx)\n",
    "encoder = Encoder(elmo_class = elmo)\n",
    "emb2seq_model = Emb2Seq_Model(encoder, decoder, vocab = vocab)\n",
    "\n",
    "# randomly initialize the weights\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)       \n",
    "emb2seq_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD_IDX: 0\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "optimizer = optim.Adam(emb2seq_model.parameters())\n",
    "PAD_IDX = vocab('<pad>')\n",
    "print('PAD_IDX: {}'.format(PAD_IDX))\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "# turn the given definition into its index list form\n",
    "def def2idx(definition, max_length, vocab):\n",
    "    \n",
    "    # definition is given by the WN NLTK API in a string\n",
    "    def_tokens = nltk.tokenize.word_tokenize(definition.lower())\n",
    "    \n",
    "    # limit the length if too long, trim\n",
    "    if len(def_tokens) > (max_length - 2):\n",
    "        def_tokens = def_tokens[0:(max_length - 2)]\n",
    "        \n",
    "        # add the start and end symbol\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "    \n",
    "    # if the length is too short, pad\n",
    "    elif len(def_tokens) < (max_length - 2):\n",
    "        \n",
    "        # add the start and end symbol\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "        \n",
    "        pad = ['<pad>'] * (max_length - len(def_tokens))\n",
    "        def_tokens = def_tokens + pad\n",
    "        \n",
    "    else:\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "            \n",
    "    # get the index for each element in the token list\n",
    "    def_idx_list = [vocab(token) for token in def_tokens]\n",
    "    \n",
    "    return def_idx_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the SemCor training data\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('../../Downloads/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml')\n",
    "\n",
    "corpus = tree.getroot()\n",
    "\n",
    "# parse the target sense tag \n",
    "target_file = open(\"../../Downloads/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_size = 1\n",
    "small_dev_size = 1\n",
    "\n",
    "# the training function\n",
    "def train(model, optimizer, corpus, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for sub_corpus in corpus:\n",
    "    \n",
    "        for sentence in sub_corpus:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get the plain text sentence\n",
    "            sentence = [word.text for word in sentence]\n",
    "            \n",
    "            # get the tagged ambiguous words\n",
    "            tagged_sent = [instance for instance in sentence if instance.tag == 'instance']\n",
    "            print(sentence)\n",
    "            print(tagged_sent)\n",
    "            \n",
    "            # only use sentence with at least one tagged word\n",
    "            if len(tagged_sent) > 0:\n",
    "                \n",
    "                # get all-word definitions, batch_size is the sentence length\n",
    "                # [batch_size, self.max_length]\n",
    "                definitions = []\n",
    "                for instance in tagged_sent:\n",
    "                    \n",
    "                    # get the sense from the WN\n",
    "                    # senses are in-order already\n",
    "                    key = f.readline().replace('\\n', '').split(' ')[-1]\n",
    "                    definition = wn.lemma_from_key(key).synset().definition()                 \n",
    "                    def_idx_list = def2idx(definition, model.max_length, vocab)\n",
    "                    definitions.append(def_idx_list)\n",
    "\n",
    "                # get the encoder-decoder result\n",
    "                # (self.max_length, batch_size, vocab_size)\n",
    "                output, result = model(sentence, tagged_sent, definitions, teacher_forcing_ratio = 0.4)\n",
    "\n",
    "                # adjust dimension for loss calculation\n",
    "                output = output.permute(1, 2, 0)\n",
    "                # print(output.shape)\n",
    "                target = torch.tensor(definitions, dtype = torch.long)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "\n",
    "                # add clip for gradient boost\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / small_test_size, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate(model, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for idx in range(small_dev_size):\n",
    "\n",
    "            # get the semcor tagged sentence\n",
    "            sentence = semcor.sents()[idx + small_train_size]\n",
    "            tagged_sent = semcor.tagged_sents(tag = 'sem')[idx + small_train_size]\n",
    "            print(idx)\n",
    "\n",
    "            # get all-word definitions\n",
    "            # [batch_size, self.max_length]\n",
    "            definitions = []\n",
    "            for idx, chunk in enumerate(tagged_sent):\n",
    "                if isinstance(chunk, Tree):\n",
    "\n",
    "                    # only take in ambiguous words\n",
    "                    if isinstance(chunk.label(), nltk.corpus.reader.wordnet.Lemma):\n",
    "                        # print(chunk.label())\n",
    "                        synset = chunk.label().synset().name()\n",
    "                        definition = wn.synset(synset).definition()\n",
    "                        \n",
    "                        print(definition)\n",
    "                        def_idx_list = def2idx(definition, model.max_length, vocab)\n",
    "                        definitions.append(def_idx_list)\n",
    "\n",
    "            # get the encoder-decoder result\n",
    "            # (max_length, batch_size, vocab_size)\n",
    "            # turn off teacher forcing\n",
    "            output, result = model(sentence, tagged_sent, definitions, teacher_forcing_ratio = 0)\n",
    "\n",
    "            # adjust dimension for loss calculation\n",
    "            output = output.permute(1, 2, 0)\n",
    "            # print(output.shape)\n",
    "            target = torch.tensor(definitions, dtype = torch.long)\n",
    "\n",
    "            loss = criterion(output, target)            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / small_dev_size, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time used by each epoch\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1'], ['.']]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a8d7f8a9c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb2seq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb2seq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f20d85161c97>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# get the encoder-decoder result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# (self.max_length, batch_size, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# adjust dimension for loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decoding-Word-Sense/emb2seq_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence, tagged_sent, definition, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;31m# sense embedding from the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# (seq_length, 256): batch is the seq_length for all-word WSD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mencoder_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# print(encoder_embedding.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decoding-Word-Sense/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence, tagged_sent)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# Extract the new word embedding for all tagged words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m# (new_seq, batch, num_directions * hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mprocessed_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;31m# Run fine-tuning MLP on new word embedding and get sense embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decoding-Word-Sense/encoder.py\u001b[0m in \u001b[0;36m_process_embedding\u001b[0;34m(self, embedding, tagged_sent)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;31m# concate the all-word embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# (new_seq, num_directions * hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "import time\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, _ = train(emb2seq_model, optimizer, criterion, CLIP)\n",
    "    valid_loss, result = evaluate(emb2seq_model, criterion)\n",
    "    print(result)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # visualize the results\n",
    "    for n in range(len(result[0])):\n",
    "        sense = []\n",
    "        for m in range(len(result)):\n",
    "            w = vocab.idx2word.get(int(result[m][n]))\n",
    "            sense.append(w)\n",
    "        print(sense)\n",
    "    \n",
    "    # save the best model based on the dev set\n",
    "    '''\n",
    "    if valid_loss <= best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq_model.state_dict(), 'best_model.pth')\n",
    "    '''\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "with open('train_loss.tsv', mode = 'w') as loss_file:\n",
    "        \n",
    "    csv_writer = csv.writer(loss_file)\n",
    "    csv_writer.writerow(train_losses)\n",
    "\n",
    "    \n",
    "with open('dev_loss.tsv', mode = 'w') as loss_file:\n",
    "        \n",
    "    csv_writer = csv.writer(loss_file)\n",
    "    csv_writer.writerow(dev_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "# rc('text', usetex = True)\n",
    "rc('font', family='serif')\n",
    "plt.grid(True, ls = '-.',alpha = 0.4)\n",
    "plt.plot(train_losses, ms = 4, marker = 's', label = \"Train Loss\")\n",
    "plt.legend(loc = \"best\")\n",
    "title = \"Cosine Similarity Loss (number of examples: \" + str(len(train_X)) + \")\"\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "# rc('text', usetex = True)\n",
    "rc('font', family='serif')\n",
    "plt.grid(True, ls = '-.',alpha = 0.4)\n",
    "plt.plot(dev_losses, ms = 4, marker = 'o', label = \"Dev Loss\")\n",
    "plt.legend(loc = \"best\")\n",
    "title = \"Cosine Similarity Loss (number of examples: \" + str(len(dev_X)) + \")\"\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.tight_layout()\n",
    "plt.savefig('dev_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
