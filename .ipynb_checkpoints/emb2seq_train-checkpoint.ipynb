{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import string\n",
    "import itertools\n",
    "from io import open\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Iterable, defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSEED = 1234\\nrandom.seed(SEED)\\ntorch.manual_seed(SEED)\\ntorch.backends.cudnn.deterministic = True\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set determinstic results\n",
    "'''\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Size of vocab: 17764\n"
     ]
    }
   ],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "elmo = ElmoEmbedder()\n",
    "\n",
    "from encoder import *\n",
    "from decoder import *\n",
    "from emb2seq_model import *\n",
    "\n",
    "# get the decoder vocab\n",
    "with open('./data/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    print(\"Size of vocab: {}\".format(vocab.idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the auxiliary transformer-xl for the decoder grammar\n",
    "from pytorch_pretrained_bert import TransfoXLTokenizer, TransfoXLModel, TransfoXLLMHeadModel\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary from wikitext 103)\n",
    "tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
    "# Load pre-trained model (weights)\n",
    "trans_model = TransfoXLLMHeadModel.from_pretrained('transfo-xl-wt103')\n",
    "trans_model.eval()\n",
    "trans_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([512, 3072])\n",
      "bias torch.Size([512])\n",
      "weight_ih_l0 torch.Size([1024, 512])\n",
      "weight_hh_l0 torch.Size([1024, 256])\n",
      "bias_ih_l0 torch.Size([1024])\n",
      "bias_hh_l0 torch.Size([1024])\n",
      "weight_ih_l0_reverse torch.Size([1024, 512])\n",
      "weight_hh_l0_reverse torch.Size([1024, 256])\n",
      "bias_ih_l0_reverse torch.Size([1024])\n",
      "bias_hh_l0_reverse torch.Size([1024])\n",
      "weight_ih_l1 torch.Size([1024, 512])\n",
      "weight_hh_l1 torch.Size([1024, 256])\n",
      "bias_ih_l1 torch.Size([1024])\n",
      "bias_hh_l1 torch.Size([1024])\n",
      "weight_ih_l1_reverse torch.Size([1024, 512])\n",
      "weight_hh_l1_reverse torch.Size([1024, 256])\n",
      "bias_ih_l1_reverse torch.Size([1024])\n",
      "bias_hh_l1_reverse torch.Size([1024])\n",
      "weight torch.Size([300, 512])\n",
      "bias torch.Size([300])\n",
      "weight torch.Size([256, 300])\n",
      "bias torch.Size([256])\n",
      "0.weight torch.Size([300, 512])\n",
      "0.bias torch.Size([300])\n",
      "3.weight torch.Size([256, 300])\n",
      "3.bias torch.Size([256])\n",
      "dimension_reduction.weight torch.Size([512, 3072])\n",
      "dimension_reduction.bias torch.Size([512])\n",
      "lstm.weight_ih_l0 torch.Size([1024, 512])\n",
      "lstm.weight_hh_l0 torch.Size([1024, 256])\n",
      "lstm.bias_ih_l0 torch.Size([1024])\n",
      "lstm.bias_hh_l0 torch.Size([1024])\n",
      "lstm.weight_ih_l0_reverse torch.Size([1024, 512])\n",
      "lstm.weight_hh_l0_reverse torch.Size([1024, 256])\n",
      "lstm.bias_ih_l0_reverse torch.Size([1024])\n",
      "lstm.bias_hh_l0_reverse torch.Size([1024])\n",
      "lstm.weight_ih_l1 torch.Size([1024, 512])\n",
      "lstm.weight_hh_l1 torch.Size([1024, 256])\n",
      "lstm.bias_ih_l1 torch.Size([1024])\n",
      "lstm.bias_hh_l1 torch.Size([1024])\n",
      "lstm.weight_ih_l1_reverse torch.Size([1024, 512])\n",
      "lstm.weight_hh_l1_reverse torch.Size([1024, 256])\n",
      "lstm.bias_ih_l1_reverse torch.Size([1024])\n",
      "lstm.bias_hh_l1_reverse torch.Size([1024])\n",
      "mlp.0.weight torch.Size([300, 512])\n",
      "mlp.0.bias torch.Size([300])\n",
      "mlp.3.weight torch.Size([256, 300])\n",
      "mlp.3.bias torch.Size([256])\n",
      "weight_ih torch.Size([1024, 512])\n",
      "weight_hh torch.Size([1024, 256])\n",
      "bias_ih torch.Size([1024])\n",
      "bias_hh torch.Size([1024])\n",
      "weight torch.Size([17764, 256])\n",
      "bias torch.Size([17764])\n",
      "lstm_cell.weight_ih torch.Size([1024, 512])\n",
      "lstm_cell.weight_hh torch.Size([1024, 256])\n",
      "lstm_cell.bias_ih torch.Size([1024])\n",
      "lstm_cell.bias_hh torch.Size([1024])\n",
      "linear.weight torch.Size([17764, 256])\n",
      "linear.bias torch.Size([17764])\n",
      "weight torch.Size([17764, 256])\n",
      "encoder.dimension_reduction.weight torch.Size([512, 3072])\n",
      "encoder.dimension_reduction.bias torch.Size([512])\n",
      "encoder.lstm.weight_ih_l0 torch.Size([1024, 512])\n",
      "encoder.lstm.weight_hh_l0 torch.Size([1024, 256])\n",
      "encoder.lstm.bias_ih_l0 torch.Size([1024])\n",
      "encoder.lstm.bias_hh_l0 torch.Size([1024])\n",
      "encoder.lstm.weight_ih_l0_reverse torch.Size([1024, 512])\n",
      "encoder.lstm.weight_hh_l0_reverse torch.Size([1024, 256])\n",
      "encoder.lstm.bias_ih_l0_reverse torch.Size([1024])\n",
      "encoder.lstm.bias_hh_l0_reverse torch.Size([1024])\n",
      "encoder.lstm.weight_ih_l1 torch.Size([1024, 512])\n",
      "encoder.lstm.weight_hh_l1 torch.Size([1024, 256])\n",
      "encoder.lstm.bias_ih_l1 torch.Size([1024])\n",
      "encoder.lstm.bias_hh_l1 torch.Size([1024])\n",
      "encoder.lstm.weight_ih_l1_reverse torch.Size([1024, 512])\n",
      "encoder.lstm.weight_hh_l1_reverse torch.Size([1024, 256])\n",
      "encoder.lstm.bias_ih_l1_reverse torch.Size([1024])\n",
      "encoder.lstm.bias_hh_l1_reverse torch.Size([1024])\n",
      "encoder.mlp.0.weight torch.Size([300, 512])\n",
      "encoder.mlp.0.bias torch.Size([300])\n",
      "encoder.mlp.3.weight torch.Size([256, 300])\n",
      "encoder.mlp.3.bias torch.Size([256])\n",
      "decoder.lstm_cell.weight_ih torch.Size([1024, 512])\n",
      "decoder.lstm_cell.weight_hh torch.Size([1024, 256])\n",
      "decoder.lstm_cell.bias_ih torch.Size([1024])\n",
      "decoder.lstm_cell.bias_hh torch.Size([1024])\n",
      "decoder.linear.weight torch.Size([17764, 256])\n",
      "decoder.linear.bias torch.Size([17764])\n",
      "embed.weight torch.Size([17764, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Emb2Seq_Model(\n",
       "  (encoder): Encoder(\n",
       "    (dimension_reduction): Linear(in_features=3072, out_features=512, bias=True)\n",
       "    (lstm): LSTM(512, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=300, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1)\n",
       "      (3): Linear(in_features=300, out_features=256, bias=True)\n",
       "      (4): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm_cell): LSTMCell(512, 256)\n",
       "    (linear): Linear(in_features=256, out_features=17764, bias=True)\n",
       "  )\n",
       "  (embed): Embedding(17764, 256, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some hyperparameters\n",
    "max_seq_length = 15\n",
    "decoder_hidden_size = 256\n",
    "\n",
    "# please check the emb2seq_parallel_train.py for CUDA parallel version \n",
    "decoder = Decoder(\n",
    "    vocab_size = vocab.idx, \n",
    "    max_seq_length = max_seq_length, \n",
    "    hidden_size = decoder_hidden_size)\n",
    "\n",
    "encoder = Encoder(elmo_class = elmo)\n",
    "\n",
    "emb2seq_model = Emb2Seq_Model(\n",
    "    encoder, \n",
    "    decoder, \n",
    "    vocab = vocab, \n",
    "    max_seq_length = max_seq_length, \n",
    "    decoder_hidden_size = decoder_hidden_size)\n",
    "\n",
    "# randomly initialize the weights\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.shape)\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "emb2seq_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "PAD_IDX: 0\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# training hyperparameters\n",
    "optimizer = optim.Adam(emb2seq_model.parameters())\n",
    "PAD_IDX = vocab('<pad>')\n",
    "print('PAD_IDX: {}'.format(PAD_IDX))\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "# turn the given definition into its index list form\n",
    "def def2idx(definition, max_length, vocab):\n",
    "    \n",
    "    # definition is given by the WN NLTK API in a string\n",
    "    def_tokens = nltk.tokenize.word_tokenize(definition.lower())\n",
    "    \n",
    "    # limit the length if too long, trim\n",
    "    if len(def_tokens) > (max_length - 2):\n",
    "        def_tokens = def_tokens[0:(max_length - 2)]\n",
    "        \n",
    "        # add the start and end symbol\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "    \n",
    "    # if the length is too short, pad\n",
    "    elif len(def_tokens) < (max_length - 2):\n",
    "        \n",
    "        # add the start and end symbol\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "        \n",
    "        pad = ['<pad>'] * (max_length - len(def_tokens))\n",
    "        def_tokens = def_tokens + pad\n",
    "        \n",
    "    else:\n",
    "        def_tokens = ['<start>'] + def_tokens + ['<end>']\n",
    "            \n",
    "    # get the index for each element in the token list\n",
    "    def_idx_list = [vocab(token) for token in def_tokens]\n",
    "    \n",
    "    return def_idx_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "# get the literal and indices of the definition of the tagged word\n",
    "# SemCor for train\n",
    "def get_SemCor_def(instance):\n",
    "    key = ''\n",
    "    target_file = open(\"../WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt\", \"r\")\n",
    "    for line in target_file:\n",
    "        if line.startswith(instance.get('id')):\n",
    "            key = line.replace('\\n', '').split(' ')[-1]\n",
    "            \n",
    "    # literal definition from the WN\n",
    "    definition = wn.lemma_from_key(key).synset().definition()\n",
    "    return definition\n",
    "\n",
    "# SemEval 2007 for dev\n",
    "def get_SemEval_def(instance):\n",
    "    key = ''\n",
    "    target_file = open(\"../WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.gold.key.txt\", \"r\")\n",
    "    for line in target_file:\n",
    "        if line.startswith(instance.get('id')):\n",
    "            key = line.replace('\\n', '').split(' ')[-1]\n",
    "            \n",
    "    # literal definition from the WN\n",
    "    definition = wn.lemma_from_key(key).synset().definition()\n",
    "    return definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the SemCor training data\n",
    "import xml.etree.ElementTree as ET\n",
    "semcor_tree = ET.parse('../WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml')\n",
    "semcor_corpus = semcor_tree.getroot()\n",
    "\n",
    "# parse the SemEval dev data\n",
    "semeval_tree = ET.parse('../WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml')\n",
    "semeval_corpus = semeval_tree.getroot()\n",
    "\n",
    "# small train and test sets\n",
    "small_train_size = 1\n",
    "small_dev_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training function\n",
    "def train(model, optimizer, corpus, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    sentence_num = 0\n",
    "    \n",
    "    for sub_corpus in corpus[0:small_train_size]:\n",
    "    \n",
    "        for sent in sub_corpus[0:20]:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # get the plain text sentence\n",
    "            sentence = [word.text for word in sent]\n",
    "            \n",
    "            # get the tagged ambiguous words\n",
    "            tagged_sent = [instance for instance in sent if instance.tag == 'instance']\n",
    "            # print(sentence)\n",
    "            # print(tagged_sent)\n",
    "            \n",
    "            # only use sentence with at least one tagged word\n",
    "            if len(tagged_sent) > 0:\n",
    "                \n",
    "                sentence_num += 1\n",
    "                \n",
    "                # get all-word definitions, batch_size is the sentence length\n",
    "                # [batch_size, self.max_length]\n",
    "                definitions = []\n",
    "                for instance in tagged_sent:\n",
    "                    \n",
    "                    # get the sense from the target file with ID\n",
    "                    definition = get_SemCor_def(instance)\n",
    "                    def_idx_list = def2idx(definition, model.max_length, vocab)\n",
    "                    definitions.append(def_idx_list)\n",
    "\n",
    "                # get the encoder-decoder result\n",
    "                # (self.max_length, batch_size, vocab_size)\n",
    "                output, _ = model(sentence, \n",
    "                                  tagged_sent, \n",
    "                                  definitions, \n",
    "                                  trans_model, \n",
    "                                  teacher_forcing_ratio = 0.4)\n",
    "                \n",
    "                # adjust dimension for loss calculation\n",
    "                # (self.max_length * batch_size, vocab_size)\n",
    "                output = output.view(-1, output.shape[-1])\n",
    "                target = torch.tensor(definitions, dtype = torch.long).to(device)\n",
    "                # (self.max_length * batch_size)\n",
    "                target = torch.transpose(target, 0, 1).contiguous().view(-1)\n",
    "                '''\n",
    "                output = output.permute(1, 2, 0)\n",
    "                target = torch.tensor(definitions, dtype = torch.long).to(device)\n",
    "                '''\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "\n",
    "                # add clip for gradient boost\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "    return epoch_loss / sentence_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate(model, corpus, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    sentence_num = 0\n",
    "\n",
    "    # result from all dev sentences, both idx form and literal form\n",
    "    all_definitions = []\n",
    "    all_sentence_result = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for sub_corpus in corpus[0:small_dev_size]:\n",
    "    \n",
    "            for sent in sub_corpus[0:5]:\n",
    "                \n",
    "                sentence = [word.text for word in sent]\n",
    "                \n",
    "                # get the tagged ambiguous words\n",
    "                tagged_sent = [instance for instance in sent if instance.tag == 'instance']\n",
    "                # print(sentence)\n",
    "                # print(tagged_sent)\n",
    "\n",
    "                # only use sentence with at least one tagged word\n",
    "                if len(tagged_sent) > 0:\n",
    "                    sentence_num += 1\n",
    "\n",
    "                    # get all-word definitions, batch_size is the sentence length\n",
    "                    # [batch_size, self.max_length]\n",
    "                    definitions = []\n",
    "                    literal_def = []\n",
    "                    for instance in tagged_sent:\n",
    "\n",
    "                        # get the sense from the target file with ID\n",
    "                        definition = get_SemEval_def(instance)\n",
    "                        def_idx_list = def2idx(definition, model.max_length, vocab)\n",
    "                        definitions.append(def_idx_list)\n",
    "                        literal_def.append(definition)\n",
    "\n",
    "                    # get the encoder-decoder result\n",
    "                    # (self.max_length, batch_size, vocab_size)\n",
    "                    output, result = model(sentence, \n",
    "                                           tagged_sent, \n",
    "                                           definitions, \n",
    "                                           trans_model, \n",
    "                                           teacher_forcing_ratio = 0)\n",
    "                    all_sentence_result.append(result)\n",
    "                    all_definitions.append(literal_def)\n",
    "                    \n",
    "                    # adjust dimension for loss calculation\n",
    "                    # (self.max_length * batch_size, vocab_size)\n",
    "                    output = output.view(-1, output.shape[-1])\n",
    "                    target = torch.tensor(definitions, dtype = torch.long).to(device)\n",
    "                    # (self.max_length * batch_size)\n",
    "                    target = torch.transpose(target, 0, 1).contiguous().view(-1)\n",
    "                    '''\n",
    "                    output = output.permute(1, 2, 0)\n",
    "                    target = torch.tensor(definitions, dtype = torch.long).to(device)\n",
    "                    '''\n",
    "                    loss = criterion(output, target)        \n",
    "                    epoch_loss += loss.item()\n",
    "                    \n",
    "    return epoch_loss / sentence_num, all_sentence_result, all_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time used by each epoch\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "# arrange the result back to literal readable form\n",
    "def arrange_result(all_sentence_result):\n",
    "    arranged_all_sentence_result = []\n",
    "    for result in all_sentence_result:\n",
    "        arranged_results = []\n",
    "        for n in range(len(result[0])):\n",
    "            sense = ''\n",
    "            for m in range(len(result)):\n",
    "                w = ' '+ vocab.idx2word.get(int(result[m][n]))\n",
    "                sense += w\n",
    "            arranged_results.append(sense)\n",
    "        arranged_all_sentence_result.append(arranged_results)\n",
    "    return arranged_all_sentence_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "# write the results to the file, with the ground-truth\n",
    "def write_result_to_file(arranged_all_sentence_result, all_definition):\n",
    "    with open('result.txt', 'w') as f:\n",
    "        for idx, arranged_results in enumerate(arranged_all_sentence_result):\n",
    "            f.write(\"sentence {}\\n\".format(idx))\n",
    "\n",
    "            for literal_def in all_definitions[idx]:\n",
    "                f.write(\"%s\\n\" % literal_def)\n",
    "\n",
    "            for item in arranged_results:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-04bfa065dd71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb2seq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemcor_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a330f11b3315>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, corpus, criterion, clip)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# get the encoder-decoder result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# (self.max_length, batch_size, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagged_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# adjust dimension for loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decoding-Word-Sense/emb2seq_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence, tagged_sent, definition, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    152\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                 \u001b[0mtrans_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trans_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrans_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decoding-Word-Sense/emb2seq_model.py\u001b[0m in \u001b[0;36m_get_trans_prob\u001b[0;34m(self, result, batch_size, mem)\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                 \u001b[0;31m# We can re-use the memory cells in a subsequent call to attend a longer context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                 \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# get the log probability for predicted last token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling_transfo_xl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, target, mems)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0mtgt_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0mlast_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mpred_hid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling_transfo_xl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, mems)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mmems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_mems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mlast_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;31m# We transpose back here to shape [bsz, len, hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling_transfo_xl.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, dec_inp, mems)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0mhids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0mmems_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m                 \u001b[0mcore_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_attn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# learnable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mcore_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling_transfo_xl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_inp, r, dec_attn_mask, mems)\u001b[0m\n\u001b[1;32m    744\u001b[0m         output = self.dec_attn(dec_inp, r,\n\u001b[1;32m    745\u001b[0m                                \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_attn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                                mems=mems)\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling_transfo_xl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, w, r, attn_mask, mems)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;31m#### compute attention vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mattn_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijbn,jbnd->ibnd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_head_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# [qlen x bsz x n_head x d_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# the old interface of passing the operands as one list argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0moperands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "import time\n",
    "\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "train_losses = []\n",
    "dev_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(emb2seq_model, optimizer, semcor_corpus, criterion, CLIP)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    valid_loss, all_sentence_result, all_definitions = evaluate(emb2seq_model, semeval_corpus, criterion)\n",
    "    dev_losses.append(valid_loss)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # visualize the results\n",
    "    arranged_all_sentence_result = arrange_result(all_sentence_result)\n",
    "            \n",
    "    # save the best model based on the dev set\n",
    "    if valid_loss <= best_valid_loss:\n",
    "\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(emb2seq_model.state_dict(), 'emb2seq_best_model.pth')\n",
    "        \n",
    "        # record the result\n",
    "        write_result_to_file(arranged_all_sentence_result, all_definitions)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "with open('train_loss.tsv', mode = 'w') as loss_file:\n",
    "    csv_writer = csv.writer(loss_file)\n",
    "    csv_writer.writerow(train_losses)\n",
    "\n",
    "with open('dev_loss.tsv', mode = 'w') as loss_file: \n",
    "    csv_writer = csv.writer(loss_file)\n",
    "    csv_writer.writerow(dev_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "# rc('text', usetex = True)\n",
    "rc('font', family='serif')\n",
    "plt.grid(True, ls = '-.',alpha = 0.4)\n",
    "plt.plot(train_losses, ms = 4, marker = 's', label = \"Train Loss\")\n",
    "plt.legend(loc = \"best\")\n",
    "title = \"CrossEntropy Loss\"\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "# rc('text', usetex = True)\n",
    "rc('font', family='serif')\n",
    "plt.grid(True, ls = '-.',alpha = 0.4)\n",
    "plt.plot(dev_losses, ms = 4, marker = 'o', label = \"Dev Loss\")\n",
    "plt.legend(loc = \"best\")\n",
    "title = \"CrossEntropy Loss\"\n",
    "plt.title(title)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.tight_layout()\n",
    "plt.savefig('dev_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
